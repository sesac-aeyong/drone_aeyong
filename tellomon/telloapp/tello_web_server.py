# tello_web_server.py
import math
import os
import traceback
import cv2
import patches
from djitellopy import Tello
import threading
import time
import numpy as np
import queue
import os
from datetime import datetime
from hailorun import HailoRun
from yolo_tools import draw_detections_on_frame
from .app_tools import *
from settings import settings as S

class TelloOpticalFlow:
    def __init__(self, tello_instance, drone_color='blue'):
        self.tello = tello_instance
        self.is_optical_flow_running = True
        self.lock = ... # (ê¸°ì¡´ lock ê°ì²´ ë“± í•„ìš”)
        
        # ==========================================
        # 1. ë“œë¡  ì„ íƒ ë° ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ
        # ==========================================
        if drone_color == 'blue':
            # íŒŒë€ í…”ë¡œ (Tello 1)
            self.mtx = np.array([[921.73863554, 0.0, 484.9439379],
                                 [0.0, 921.06520894, 355.5162763],
                                 [0.0, 0.0, 1.0]])
            self.dist = np.array([0.01635261, -0.19644455, -0.00021575, 0.00116993, 0.56532416])
            self.new_camera_mtx = np.array([[922.83538766, 0.0, 485.70362399],
                                            [0.0, 920.62929167, 355.42781255],
                                            [0.0, 0.0, 1.0]])
            print(">>> [INFO] Loaded Calibration Data: BLUE Tello")
            
        elif drone_color == 'white':
            # í°ìƒ‰ í…”ë¡œ (Tello 2)
            self.mtx = np.array([[918.20765312, 0.0, 481.1811003],
                                 [0.0, 918.144143, 351.56850948],
                                 [0.0, 0.0, 1.0]])
            self.dist = np.array([0.01513358, -0.32789949, -0.00590646, -0.00200168, 0.96440547])
            self.new_camera_mtx = np.array([[917.04620423, 0.0, 479.64715048],
                                            [0.0, 914.76700761, 348.73281015],
                                            [0.0, 0.0, 1.0]])
            print(">>> [INFO] Loaded Calibration Data: WHITE Tello")

        # ì •í™•í•œ ì´ˆì ê±°ë¦¬ (fx) ì¶”ì¶œ (Undistort í›„ì˜ newCameraMatrix ì‚¬ìš©)
        self.fx = self.new_camera_mtx[0, 0] 
        
        # Optical Flow íŒŒë¼ë¯¸í„°
        self.of_lk_params = dict(winSize=(15, 15), maxLevel=2,
                                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))
        self.of_max_corners = 100
        self.of_quality = 0.3
        self.of_min_dist = 7

class TelloWebServer:
    def __init__(self, socketio):
        self.tello = None
        self.socketio = socketio
        self.is_streaming = False
        self.is_connected = False
        self.current_frame = None
        self.current_depth_map = None            # float32 depth (m) visualized by depth_feed
        self.current_detections = []
        self.target_class = None
        self.target_track_id = None
        self.target_bbox = None  # Store in [x1, y1, x2, y2] format
        self.is_tracking = False
        self.battery = 0
        self.height = 0
        self.lock = threading.Lock()
        self.frame_center = (480, 360)
        self.target_depth = None

        # RC ëª…ë ¹ ì„¤ì •
        self.use_rc_for_manual = False
        self.use_rc_for_tracking = True
        self.rc_speed = 40
        self.tracking_rc_speed = 25
        self.rc_command_duration = 0.4

        # ì›¹ ë¡œê·¸ ì‹œìŠ¤í…œ
        self.log_queue = queue.Queue(maxsize=100)  # ìµœëŒ€ 100ê°œ ë¡œê·¸ ì €ì¥
        self.log_thread = None
        self.is_logging = True
        self.start_log_broadcaster()

        # ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”
        self.log("INFO", "Loading inference engine...")
        try:
            self.inference_engine = HailoRun()
            self.inference_engine.load()
            self.log("SUCCESS", "âœ… Inference engine loaded successfully")
        except Exception as e:
            self.log("ERROR", f"âŒ Failed to load inference engine: {e}")
            import traceback
            traceback.print_exc()
            self.inference_engine = None

        # --- Optical Flow ê´€ë ¨ ìƒíƒœ/íŒŒë¼ë¯¸í„° ---
        # focal (í”½ì…€) - ê¸°ë³¸ê°’ì€ ë„¤ê°€ ì¤¬ë˜ fx ê°’ ì‚¬ìš©
        self.focal_px = 922.837110
        self.of_max_corners = 300
        self.of_quality = 0.01
        self.of_min_dist = 7
        self.of_lk_params = dict(winSize=(21, 21), maxLevel=3,
                                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))
        self.of_bg_percentile = 30          # í•˜ìœ„ í¼ì„¼íƒ€ì¼ì„ background í›„ë³´ë¡œ
        self.is_optical_flow_running = False
        self.optical_flow_thread_obj = None
        self.of_last_stats = {}
        self.of_blur_kernel = 51            # sparse->dense ì‹œ Gaussian blur kernel (í™€ìˆ˜)
        # ìµœì†Œ ì „ì§„ ì†ë„ (m/s) ì•ˆì •í™”
        self.min_forward_speed = 0.02

        # ë…¹í™” ê´€ë ¨ ë³€ìˆ˜ ì¶”ê°€
        self.is_recording = False
        self.video_writer = None
        self.recording_filename = None
        self.recording_dir = "recordings"
        if not os.path.exists(self.recording_dir):
            os.makedirs(self.recording_dir)
            self.log("INFO", f"ğŸ“ Recording directory created: {self.recording_dir}")

        # # ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        # self.screenshot_dir = "screenshots"
        # if not os.path.exists(self.screenshot_dir):
        #     os.makedirs(self.screenshot_dir)
        #     self.log("INFO", f"ğŸ“ Screenshot directory created: {self.screenshot_dir}")

    # ----------------------
    # ë¡œê¹…
    # ----------------------
    def log(self, level, message):
        import datetime
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        log_entry = {
            'timestamp': timestamp,
            'level': level,
            'message': message
        }

        # í„°ë¯¸ë„ ì¶œë ¥
        if level == "ERROR":
            print(f"[{timestamp}] âŒ {message}")
        elif level == "SUCCESS":
            print(f"[{timestamp}] âœ… {message}")
        elif level == "WARNING":
            print(f"[{timestamp}] âš ï¸ {message}")
        elif level == "DEBUG":
            print(f"[{timestamp}] ğŸ” {message}")
        else:
            print(f"[{timestamp}] â„¹ï¸ {message}")

        # ì›¹ìœ¼ë¡œ ì „ì†¡ (íì— ì¶”ê°€)
        try:
            if self.log_queue.full():
                self.log_queue.get()
            self.log_queue.put(log_entry)
        except:
            pass

    def start_log_broadcaster(self):
        """ë¡œê·¸ë¥¼ ì›¹ìœ¼ë¡œ ì „ì†¡í•˜ëŠ” ìŠ¤ë ˆë“œ ì‹œì‘"""
        def broadcast_logs():
            while self.is_logging:
                try:
                    log_entry = self.log_queue.get(timeout=0.5)
                    self.socketio.emit('log_message', log_entry)
                except queue.Empty:
                    continue
                except Exception as e:
                    print(f"Log broadcast error: {e}")

        self.log_thread = threading.Thread(target=broadcast_logs, daemon=True)
        self.log_thread.start()

    # ----------------------
    # Tello ì—°ê²° / ìŠ¤íŠ¸ë¦¬ë°
    # ----------------------
    def connect_tello(self):
        """í…”ë¡œ ë“œë¡  ì—°ê²°"""
        try:
            self.log("INFO", "ğŸ” Checking Tello WiFi connection...")
            if not connect_to_tello_wifi():
                self.log("ERROR", "Failed to connect to Tello WiFi")
                return False

            self.log("SUCCESS", "Tello WiFi connected")
            time.sleep(2)

            # ê¸°ì¡´ ì—°ê²° ì •ë¦¬
            if self.tello:
                try:
                    self.log("INFO", "Cleaning up old connection...")
                    self.is_streaming = False
                    time.sleep(1)
                    if hasattr(self.tello, 'background_frame_read') and self.tello.background_frame_read:
                        try:
                            self.tello.background_frame_read.stop()
                        except:
                            pass
                    self.tello.streamoff()
                    time.sleep(1)
                    self.tello.end()
                except Exception as e:
                    self.log("WARNING", f"Cleanup error (ignored): {e}")
                finally:
                    self.tello = None
                    time.sleep(3)

            self.log("INFO", "Creating new Tello connection...")
            self.tello = Tello()

            max_retries = 3
            for attempt in range(max_retries):
                try:
                    self.log("INFO", f"Connection attempt {attempt + 1}/{max_retries}...")
                    self.tello.connect()
                    break
                except Exception as e:
                    self.log("WARNING", f"Attempt {attempt + 1} failed: {e}")
                    if attempt < max_retries - 1:
                        time.sleep(2)
                    else:
                        raise

            self.battery = self.tello.get_battery()
            self.log("SUCCESS", f"Tello connected. Battery: {self.battery}%")

            # ë°°í„°ë¦¬ ê²½ê³ 
            if self.battery < 20:
                self.log("WARNING", f"âš ï¸ Low battery: {self.battery}%")

            self.log("INFO", "Starting video stream...")
            try:
                self.tello.streamoff()
                time.sleep(2)
            except:
                pass

            self.tello.streamon()
            time.sleep(3)

            self.log("SUCCESS", "ğŸ¥ Stream started successfully")
            self.is_connected = True
            return True

        except Exception as e:
            self.log("ERROR", f"Connection error: {e}")
            self.is_connected = False
            self.tello = None
            return False

    # ----------------------
    # ì¶”ë¡  (ê¸°ì¡´)
    # ----------------------
    def process_frame_with_inference(self, frame):
        """ì¶”ë¡  ì—”ì§„ìœ¼ë¡œ ê°ì²´ ê°ì§€ ë° ê¹Šì´ ì¶”ì •"""
        if self.inference_engine is None:
            print("âŒ Inference engine is None!")
            return [], None

        try:
            detections, depth_map, _ = self.inference_engine.run(frame)
            return detections, depth_map
        except Exception as e:
            print(f"âŒ Inference error: {e}")
            import traceback
            traceback.print_exc()
            return [], None

    # ----------------------
    # ìë™ ì¶”ì  (ê¸°ì¡´)
    # ----------------------
    def tracking_thread(self):
        """ìë™ ì¶”ì  ìŠ¤ë ˆë“œ"""
        last_command_time = time.time()
        command_interval = 1.0
        target_lost_time = None
        target_lost_warning_sent = False
        depth_threshold = 0.20
        prev_depth = None

        self.log("INFO", "ğŸ¯ Tracking thread started (safe mode: 1s interval)")

        while self.is_tracking:
            try:
                if self.target_bbox and self.current_frame is not None:
                    current_time = time.time()

                    # íƒ€ê²Ÿ ì¬ë°œê²¬ ì‹œ ê²½ê³  ë¦¬ì…‹
                    if target_lost_time is not None:
                        self.log("SUCCESS", "ğŸ¯ Target re-acquired!")
                        target_lost_time = None
                        target_lost_warning_sent = False

                    if current_time - last_command_time >= command_interval:
                        # ì œì–´ ëª…ë ¹ ê³„ì‚°
                        h, w = self.current_frame.shape[:2]
                        center_x = w // 2
                        center_y = h // 2

                        # target_bbox is in [x1, y1, x2, y2] format
                        x1, y1, x2, y2 = self.target_bbox
                        target_center_x = (x1 + x2) // 2
                        target_center_y = (y1 + y2) // 2

                        # ì˜¤ì°¨ ê³„ì‚°
                        error_x = target_center_x - center_x
                        error_y = target_center_y - center_y
                        if prev_depth is not None:
                            error_d = self.target_depth - prev_depth
                        else:
                            error_d = None

                        # depth ê³„ì‚°
                        prev_depth = self.target_depth

                        # íƒ€ê²Ÿ í¬ê¸°
                        target_width = x2 - x1
                        target_height = y2 - y1
                        target_area = target_width * target_height
                        frame_area = w * h
                        target_ratio = target_area / frame_area

                        # ì„ê³„ê°’
                        threshold_x = w * 0.1
                        threshold_y = h * 0.1
                        threshold_size_min = 0.06
                        threshold_size_max = 0.20

                        action = None

                        # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì œì–´
                        # 1. ì¢Œìš° ì •ë ¬ (Yaw)
                        if abs(error_x) > threshold_x:
                            if self.use_rc_for_tracking:
                                yaw_speed = int(np.clip(error_x * 0.06, -self.tracking_rc_speed, self.tracking_rc_speed))
                                self.tello.send_rc_control(0, 0, 0, yaw_speed)
                                time.sleep(self.rc_command_duration)
                                self.tello.send_rc_control(0, 0, 0, 0)
                                action = f"RC yaw={yaw_speed}"
                            else:
                                angle = 15
                                if error_x > 0:
                                    self.tello.rotate_clockwise(angle)
                                    action = f"CW {angle}Â°"
                                else:
                                    self.tello.rotate_counter_clockwise(angle)
                                    action = f"CCW {angle}Â°"

                        # 3. ìƒí•˜ ì •ë ¬
                        elif abs(error_y) > threshold_y:
                            if self.use_rc_for_tracking:
                                ud_speed = int(np.clip(-error_y * 0.06, -self.tracking_rc_speed, self.tracking_rc_speed))
                                self.tello.send_rc_control(0, 0, ud_speed, 0)
                                time.sleep(self.rc_command_duration)
                                self.tello.send_rc_control(0, 0, 0, 0)
                                action = f"RC ud={ud_speed}"
                            else:
                                if error_y > 0:
                                    self.tello.move_down(20)
                                    action = "Down 20cm"
                                else:
                                    self.tello.move_up(20)
                                    action = "Up 20cm"
                        else:
                            action = "Centered âœ…"

                        if action:
                            self.log("DEBUG", f"ğŸ¯ {action} | Error: x={error_x:.0f}, y={error_y:.0f} | Size: {target_ratio:.3f}")
                            action = None

                        elif error_d and abs(error_d) > depth_threshold:
                            # ì‚¬ëŒì´ ë„ˆë¬´ ë©€ë‹¤ â†’ ì•ìœ¼ë¡œ ì´ë™í•´ì•¼ í•¨
                            if error_d > 0:
                                if self.use_rc_for_tracking:
                                    self.tello.send_rc_control(0, self.tracking_rc_speed, 0, 0)
                                    time.sleep(self.rc_command_duration)
                                    self.tello.send_rc_control(0, 0, 0, 0)
                                    action = f"RC forward (error_d={error_d:.2f})"
                                else:
                                    self.tello.move_forward(20)
                                    action = "Forward 20cm"

                        else:
                            action = "Distance OK (within threshold)"

                        if action:
                            self.log("DEBUG", f"ğŸ¯ {action} | Error: depth={error_d:.0f} | Size: {target_ratio:.3f}")
                            action = None

                        last_command_time = current_time
                        time.sleep(0.5)

                else:
                    # íƒ€ê²Ÿì„ ìƒì–´ë²„ë¦¼
                    if target_lost_time is None:
                        target_lost_time = time.time()

                    # 3ì´ˆ ì´ìƒ íƒ€ê²Ÿì„ ëª» ì°¾ìœ¼ë©´ ê²½ê³ 
                    if not target_lost_warning_sent and (time.time() - target_lost_time) > 3:
                        self.log("WARNING", f"âš ï¸ Target lost for 3 seconds (ID: {self.target_track_id})")
                        target_lost_warning_sent = True

                time.sleep(0.2)

            except Exception as e:
                self.log("ERROR", f"Tracking error: {e}")
                if self.use_rc_for_tracking:
                    try:
                        self.tello.send_rc_control(0, 0, 0, 0)
                    except:
                        pass
                time.sleep(1)

        if self.use_rc_for_tracking:
            try:
                self.tello.send_rc_control(0, 0, 0, 0)
                self.log("INFO", "ğŸ›‘ Tracking stopped - drone halted")
            except:
                pass

        self.log("INFO", "ğŸ¯ Tracking thread stopped")

    # ----------------------
    # Video stream (ê¸°ì¡´)
    # ----------------------
    def video_stream_thread(self):
        """ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ìŠ¤ë ˆë“œ"""
        print("ğŸ“¹ Starting video stream thread...")

        try:
            self.frame_reader = self.tello.get_frame_read()
            print("âœ… Frame reader initialized")
        except Exception as e:
            print(f"âŒ Failed to initialize frame reader: {e}")
            self.is_streaming = False
            self.socketio.emit('stream_error', {
                'message': 'Failed to start video stream. Please reconnect.'
            })
            return

        error_count = 0
        max_errors = 10

        while self.is_streaming:
            try:
                frame = self.frame_reader.frame

                if frame is not None:
                    error_count = 0

                    # BGR â†’ RGB ë³€í™˜ (inference expects RGB)
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                    # ì¶”ë¡  ì‹¤í–‰
                    detections, depth_map = self.process_frame_with_inference(frame_rgb)

                    with self.lock:
                        self.current_detections = detections
                        # inferenceì—ì„œ ë‚˜ì˜¨ depth_map í¬ê¸°ì™€ ë§ì¶”ë ¤ë©´ ì£¼ì˜
                        try:
                            if depth_map is not None:
                                self.current_depth_map = cv2.resize(depth_map, (frame.shape[1], frame.shape[0]))
                        except Exception:
                            pass

                        # íƒ€ê²Ÿ ì¶”ì ì¤‘ì´ë©´ í•´ë‹¹ ê°ì²´ ì°¾ê¸°
                        if self.is_tracking and self.target_track_id is not None:
                            target_found = False
                            for det in detections:
                                if det['track_id'] == self.target_track_id:
                                    # bbox ì—…ë°ì´íŠ¸ (detectionsëŠ” dict í¬ë§· ê°€ì •)
                                    self.target_bbox = det['bbox']
                                    self.target_class = det['class']
                                    target_found = True
                                    break

                            if not target_found:
                                self.log("WARNING", f"âš ï¸ Target ID {self.target_track_id} lost from view")
                            else:
                                x1, y1, x2, y2 = map(int, self.target_bbox)

                                # depth_mapì—ì„œ bbox ë¶€ë¶„ë§Œ crop
                                try:
                                    bbox_depth_map = self.current_depth_map[y1:y2, x1:x2]
                                except Exception:
                                    bbox_depth_map = np.array([])

                                if bbox_depth_map.size > 0:
                                    # ì¤‘ì•™ê°’ì´ ê°€ì¥ ì•ˆì •ì 
                                    target_depth = float(np.median(bbox_depth_map))

                                    # ì‹ ë¢°ë„(ì˜µì…˜)
                                    depth_conf = float(np.var(bbox_depth_map))

                                    # ì €ì¥ (ë‹¤ë¥¸ ì“°ë ˆë“œë‚˜ controllerê°€ ì“°ê²Œ)
                                    self.target_depth = target_depth
                                    self.target_depth_conf = depth_conf

                                    self.log("INFO", f"ğŸ¯ Target depth: {target_depth:.3f}, conf: {depth_conf:.5f}")
                                else:
                                    self.log("WARNING", "Target depth crop invalid")

                    # ê°ì§€ ê²°ê³¼ ê·¸ë¦¬ê¸° (inference ì—”ì§„ì˜ helper ì‚¬ìš©)
                    frame_with_detections = frame_rgb.copy()
                    try:
                        frame_with_detections = self.inference_engine.draw_detections_on_frame(
                            frame_with_detections,
                            detections,
                            target_track_id=self.target_track_id if self.is_tracking else None
                        )
                    except Exception:
                        pass

                    # í”„ë ˆì„ ì¤‘ì‹¬ ì‹­ìì„  í‘œì‹œ
                    h, w = frame_with_detections.shape[:2]
                    center_x, center_y = w // 2, h // 2
                    cv2.line(frame_with_detections, (center_x - 30, center_y), (center_x + 30, center_y), (255, 255, 255), 2)
                    cv2.line(frame_with_detections, (center_x, center_y - 30), (center_x, center_y + 30), (255, 255, 255), 2)
                    cv2.circle(frame_with_detections, (center_x, center_y), 5, (255, 255, 255), -1)

                    # ë°°í„°ë¦¬ ë° ë†’ì´ ì •ë³´ ì—…ë°ì´íŠ¸
                    try:
                        old_battery = self.battery
                        self.battery = self.tello.get_battery()
                        self.height = self.tello.get_height()

                        # ë°°í„°ë¦¬ ê²½ê³ 
                        if self.battery < 15 and old_battery >= 15:
                            self.log("WARNING", f"âš ï¸ Critical battery: {self.battery}% - Land soon!")
                        elif self.battery < 25 and old_battery >= 25:
                            self.log("WARNING", f"âš ï¸ Low battery: {self.battery}%")
                    except:
                        pass

                    # í”„ë ˆì„ ì €ì¥ (convert back to BGR for web)
                    # with self.lock:
                    #     try:
                    #         frame_bgr = cv2.cvtColor(frame_with_detections, cv2.COLOR_RGB2BGR)
                    #     except Exception:
                    #         frame_bgr = frame.copy()
                    #     self.current_frame = frame_bgr
                    
                    self.write_frame_to_video()

                    # ê°ì§€ ì •ë³´ë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
                    self.socketio.emit('detections_update', {
                        'detections': [det.to_dict() for det in detections],
                        'battery': self.battery,
                        'height': self.height,
                        'is_tracking': self.is_tracking,
                        'target_track_id': self.target_track_id,
                        'target_class': self.target_class
                    })

                else:
                    error_count += 1
                    if error_count >= max_errors:
                        print("âš ï¸ Too many frame errors")
                        self.is_streaming = False
                        self.socketio.emit('stream_error', {
                            'message': 'Video stream lost. Please reconnect.'
                        })
                        break

                time.sleep(0.033)

            except Exception as e:
                print(f"Stream error: {e}")
                error_count += 1
                if error_count >= max_errors:
                    print("âŒ Stream failed completely")
                    self.is_streaming = False
                    break
                time.sleep(0.1)

        print("ğŸ“¹ Video stream thread ended")

    def start_streaming(self):
        """ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ + Optical Flow ìë™ ì‹œì‘"""
        if not self.is_streaming and self.is_connected:
            self.is_streaming = True

            # frame_reader ì‹±ê¸€í†¤í™”
            if not hasattr(self, "frame_reader") or self.frame_reader is None:
                try:
                    self.frame_reader = self.tello.get_frame_read()
                    self.log("INFO", "âœ… Frame reader initialized")
                except Exception as e:
                    self.log("ERROR", f"Failed to initialize frame reader: {e}")
                    self.is_streaming = False
                    self.socketio.emit('stream_error', {'message': 'Failed to start video stream.'})
                    return False

            # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì“°ë ˆë“œ ì‹œì‘
            threading.Thread(target=self.video_stream_thread, daemon=True).start()

            # Optical Flowë„ ìë™ ì‹œì‘
            self.start_optical_flow()

            return True
        return False

    def stop_streaming(self):
        """ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€"""
        self.is_streaming = False

    # ----------------------
    # ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
    # ----------------------

    # def save_screenshot(self):
    #     """í˜„ì¬ í”„ë ˆì„ì„ ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ì €ì¥"""
    #     try:
    #         with self.lock:
    #             if self.current_frame is None:
    #                 return {'success': False, 'message': 'No frame available'}
                
    #             frame = self.current_frame.copy()
            
    #         # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ íŒŒì¼ëª… ìƒì„±
    #         timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    #         filename = f"tello_capture_{timestamp}.jpg"
    #         filepath = os.path.join(self.screenshot_dir, filename)
            
    #         # ì´ë¯¸ì§€ ì €ì¥
    #         cv2.imwrite(filepath, frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
    #         return {
    #             'success': True, 
    #             'message': f'Screenshot saved: {filename}',
    #             'filename': filename,
    #             'filepath': filepath
    #         }
            
    #     except Exception as e:
    #         self.log("ERROR", f"Screenshot error: {e}")
    #         return {'success': False, 'message': str(e)}

    # ----------------------
    # ë…¹í™” ê¸°ëŠ¥
    # ----------------------
    
    def start_recording(self):
        """ë…¹í™” ì‹œì‘"""
        try:
            if self.is_recording:
                return {'success': False, 'message': 'Already recording'}
            
            with self.lock:
                if self.current_frame is None:
                    return {'success': False, 'message': 'No frame available'}
                
                # ë¹„ë””ì˜¤ íŒŒë¼ë¯¸í„° ì„¤ì •
                frame_height, frame_width = self.current_frame.shape[:2]
                fps = 20  # FPS ì„¤ì • (ì¡°ì • ê°€ëŠ¥)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.recording_filename = f"tello_recording_{timestamp}.mp4"
            filepath = os.path.join(self.recording_dir, self.recording_filename)
            
            # VideoWriter ì´ˆê¸°í™” (XVID ì½”ë± ì‚¬ìš©)
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            self.video_writer = cv2.VideoWriter(
                filepath, 
                fourcc, 
                fps, 
                (frame_width, frame_height)
            )
            
            if not self.video_writer.isOpened():
                self.video_writer = None
                return {'success': False, 'message': 'Failed to initialize video writer'}
            
            self.is_recording = True
            self.log("SUCCESS", f"ğŸ¥ Recording started: {self.recording_filename}")
            
            return {
                'success': True,
                'message': f'Recording started: {self.recording_filename}',
                'filename': self.recording_filename
            }
            
        except Exception as e:
            self.log("ERROR", f"Recording start error: {e}")
            self.is_recording = False
            self.video_writer = None
            return {'success': False, 'message': str(e)}

    def stop_recording(self):
        """ë…¹í™” ì¤‘ì§€"""
        try:
            if not self.is_recording:
                return {'success': False, 'message': 'Not recording'}
            
            self.is_recording = False
            
            if self.video_writer is not None:
                self.video_writer.release()
                self.video_writer = None
            
            filename = self.recording_filename
            self.recording_filename = None
            
            self.log("SUCCESS", f"ğŸ¬ Recording stopped: {filename}")
            
            return {
                'success': True,
                'message': f'Recording saved: {filename}',
                'filename': filename
            }
            
        except Exception as e:
            self.log("ERROR", f"Recording stop error: {e}")
            self.is_recording = False
            self.video_writer = None
            return {'success': False, 'message': str(e)}
    
    def write_frame_to_video(self):
        """í˜„ì¬ í”„ë ˆì„ì„ ë¹„ë””ì˜¤ì— ê¸°ë¡"""
        if self.is_recording and self.video_writer is not None:
            try:
                with self.lock:
                    if self.current_frame is not None:
                        # BGR í˜•ì‹ìœ¼ë¡œ í”„ë ˆì„ ê¸°ë¡
                        self.video_writer.write(self.current_frame)
            except Exception as e:
                self.log("ERROR", f"Frame write error: {e}")

    # ----------------------
    # Optical Flow Depth ê´€ë ¨ í•¨ìˆ˜ë“¤ (ì¶”ê°€)
    # ----------------------

    def stop_optical_flow(self):
        if not self.is_optical_flow_running:
            return False
        self.is_optical_flow_running = False
        if self.optical_flow_thread_obj:
            self.optical_flow_thread_obj.join(timeout=1.0)
        self.log("INFO", "Optical flow depth thread stopped")
        return True
    

    # def optical_flow_thread(self):
    #     """Optical Flow ê¸°ë°˜ ì ˆëŒ€ ê±°ë¦¬ ê³„ì‚° (Grid Sampling + ì—ëŸ¬ ë°©ì§€)"""
        
    #     # =========================================================
    #     # 1. í…”ë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°
    #     # =========================================================
    #     # [ì˜µì…˜ A] íŒŒë€ í…”ë¡œ (Blue Tello)
    #     mtx = np.array([[921.73863554, 0.0, 484.9439379],
    #                     [0.0, 921.06520894, 355.5162763],
    #                     [0.0, 0.0, 1.0]])
    #     dist = np.array([0.01635261, -0.19644455, -0.00021575, 0.00116993, 0.56532416])
    #     new_camera_mtx = np.array([[922.83538766, 0.0, 485.70362399],
    #                             [0.0, 920.62929167, 355.42781255],
    #                             [0.0, 0.0, 1.0]])

    #     fx = new_camera_mtx[0, 0]
        
    #     # [ì„¤ì •] ê²©ì ê°„ê²© (í”½ì…€ ë‹¨ìœ„)
    #     GRID_STEP = 40 
    #     # =========================================================

    #     try:
    #         frame_reader = self.tello.get_frame_read()
    #     except Exception as e:
    #         self.log("ERROR", f"OpticalFlow: failed to get frame_read: {e}")
    #         self.is_optical_flow_running = False
    #         return

    #     prev_gray = None
    #     prev_pts = None
    #     prev_time = time.time()

    #     while self.is_optical_flow_running:
    #         # 1. í”„ë ˆì„ íšë“
    #         raw_frame = frame_reader.frame
    #         if raw_frame is None:
    #             time.sleep(0.01)
    #             continue

    #         # 2. ì™œê³¡ ë³´ì • (Undistort)
    #         frame = cv2.undistort(raw_frame, mtx, dist, None, new_camera_mtx)
    #         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    #         # =========================================================
    #         # [ì—ëŸ¬ ë°©ì§€ 1] í•´ìƒë„ ë³€ê²½ ê°ì§€
    #         # ì´ì „ í”„ë ˆì„ê³¼ í˜„ì¬ í”„ë ˆì„ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ë¦¬ì…‹í•©ë‹ˆë‹¤.
    #         # =========================================================
    #         if prev_gray is not None and prev_gray.shape != gray.shape:
    #             print(f"[Warning] Frame size changed: {prev_gray.shape} -> {gray.shape}. Resetting Flow.")
    #             prev_gray = None
    #             prev_pts = None

    #         # 3. íŠ¹ì§•ì (ê²©ì) ìƒì„±
    #         # ì´ˆê¸° ìƒíƒœì´ê±°ë‚˜, ì ì´ ë„ˆë¬´ ì ê²Œ ë‚¨ì•˜ê±°ë‚˜, ë¦¬ì…‹ëœ ê²½ìš°
    #         if prev_gray is None or prev_pts is None or len(prev_pts) < 50:
    #             h, w = gray.shape
                
    #             # np.mgridë¥¼ ì‚¬ìš©í•˜ì—¬ ê²©ì ì¢Œí‘œ ìƒì„±
    #             grid_y, grid_x = np.mgrid[GRID_STEP//2:h:GRID_STEP, GRID_STEP//2:w:GRID_STEP].astype(np.float32)
                
    #             # (N, 1, 2) í˜•íƒœë¡œ ë³€í™˜
    #             prev_pts = np.expand_dims(np.stack((grid_x.flatten(), grid_y.flatten()), axis=1), axis=1)
                
    #             prev_gray = gray
    #             prev_time = time.time()
    #             time.sleep(0.01)
    #             continue

    #         # 4. Optical Flow ê³„ì‚° (Lucas-Kanade)
    #         # =========================================================
    #         # [ì—ëŸ¬ ë°©ì§€ 2] try-exceptë¡œ ê°ì‹¸ì„œ í¬ë˜ì‹œ ë°©ì§€
    #         # =========================================================
    #         try:
    #             next_pts, status, _ = cv2.calcOpticalFlowPyrLK(
    #                 prev_gray, gray, prev_pts, None, **self.of_lk_params
    #             )
    #         except cv2.error as e:
    #             # OpenCV ì—ëŸ¬ ë°œìƒ ì‹œ(í¬ê¸° ë¶ˆì¼ì¹˜ ë“±) ë¦¬ì…‹í•˜ê³  ë„˜ì–´ê°
    #             print(f"[Error] calcOpticalFlowPyrLK failed: {e}")
    #             prev_gray = None
    #             prev_pts = None
    #             continue

    #         # ì¶”ì  ì„±ê³µí•œ ì ë“¤ë§Œ ìœ ì§€
    #         good_prev = prev_pts[status == 1]
    #         good_next = next_pts[status == 1]

    #         # ì¶”ì  ì ì´ ë„ˆë¬´ ì ìœ¼ë©´ ë‹¤ìŒ ë£¨í”„ì—ì„œ ì¬ìƒì„±í•˜ë„ë¡ ìœ ë„
    #         if len(good_prev) < 10:
    #             prev_gray = None
    #             continue

    #         vis = frame.copy()

    #         # =========================================================
    #         # ê±°ë¦¬ ê³„ì‚° ë¡œì§
    #         # =========================================================
    #         current_time = time.time()
    #         dt = current_time - prev_time
    #         prev_time = current_time

    #         vx_cm = self.tello.get_speed_x()
    #         vy_cm = self.tello.get_speed_y()
    #         vz_cm = self.tello.get_speed_z()
    #         tx = vx_cm / 100.0  # m/s
    #         dx = tx * dt        # ì´ë™ ê±°ë¦¬ (m)

    #         draw_count = 0
    #         valid_points_count = 0

    #         for p0, p1 in zip(good_prev, good_next):
    #             x0, y0 = p0.ravel()
    #             x1, y1 = p1.ravel()
                
    #             u = (x1 - x0)
                
    #             # í•„í„°ë§: ì›€ì§ì„ì´ ë„ˆë¬´ ì‘ê±°ë‚˜(ë…¸ì´ì¦ˆ), ë“œë¡ ì´ ë©ˆì¶°ìˆìœ¼ë©´ ìŠ¤í‚µ
    #             if abs(u) < 0.1 or abs(dx) < 0.001:
    #                 cv2.circle(vis, (int(x1), int(y1)), 2, (0, 150, 0), -1)
    #                 continue

    #             try:
    #                 Z = (dx * fx) / u
    #             except ZeroDivisionError:
    #                 continue

    #             # ìœ íš¨ ê±°ë¦¬ í•„í„°ë§ (0 ~ 10m)
    #             if Z <= 0 or Z > 10.0:
    #                 cv2.circle(vis, (int(x1), int(y1)), 2, (0, 0, 255), -1) 
    #                 continue

    #             valid_points_count += 1
                
    #             # ì‹œê°í™”
    #             cv2.circle(vis, (int(x1), int(y1)), 3, (0, 255, 255), -1)
    #             cv2.line(vis, (int(x0), int(y0)), (int(x1), int(y1)), (0, 255, 255), 1)
                
    #             # í…ìŠ¤íŠ¸ ê°€ë…ì„± ì¡°ì ˆ (2ë²ˆì— 1ë²ˆ ì¶œë ¥)
    #             if draw_count % 2 == 0:
    #                 cv2.putText(vis, f"{Z:.1f}m", (int(x1) - 10, int(y1) - 5),
    #                             cv2.FONT_HERSHEY_SIMPLEX, 0.35, (50, 255, 255), 1)
    #             draw_count += 1

    #         # ì •ë³´ í‘œì‹œ
    #         info_text = f"Grid Mode | Speed vx: {vx_cm} cm/s | Speed vy: {vy_cm} cm/s | Speed vz: {vz_cm} cm/s | Valid: {valid_points_count}"
    #         cv2.putText(vis, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

    #         with self.lock:
    #             self.current_frame = vis

    #         # ë‹¤ìŒ í”„ë ˆì„ ì¤€ë¹„
    #         prev_gray = gray.copy()
    #         prev_pts = good_next.reshape(-1, 1, 2)

    #         time.sleep(0.01)

    def optical_flow_thread(self):
        """Optical Flow ê¸°ë°˜ ì ˆëŒ€ ê±°ë¦¬ ê³„ì‚° (goodFeaturesToTrack ì‚¬ìš©)"""
        
        # =========================================================
        # 1. í…”ë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°
        # =========================================================
        # [ì˜µì…˜ A] íŒŒë€ í…”ë¡œ (Blue Tello) - ì£¼ì„ ì²˜ë¦¬ë¨
        # mtx = np.array([[921.73863554, 0.0, 484.9439379],
        #                 [0.0, 921.06520894, 355.5162763],
        #                 [0.0, 0.0, 1.0]])
        # dist = np.array([0.01635261, -0.19644455, -0.00021575, 0.00116993, 0.56532416])
        # new_camera_mtx = np.array([[922.83538766, 0.0, 485.70362399],
        #                            [0.0, 920.62929167, 355.42781255],
        #                            [0.0, 0.0, 1.0]])

        # [ì˜µì…˜ B] í°ìƒ‰ í…”ë¡œ (White Tello) - í˜„ì¬ ì ìš© ì¤‘!
        # ë³´ë‚´ì£¼ì‹  ì›ë³¸ Intrinsic (fx, fy, cx, cy) ì ìš©
        mtx = np.array([[918.21, 0.0, 481.18],
                        [0.0, 918.14, 351.57],
                        [0.0, 0.0, 1.0]])
        
        # ë³´ë‚´ì£¼ì‹  Distortion Coefficients
        dist = np.array([0.01513, -0.32790, -0.005906, -0.002002, 0.96441])
        
        # ë³´ë‚´ì£¼ì‹  New Camera Matrix (Undistort í›„)
        new_camera_mtx = np.array([[917.04620423, 0.0, 479.64715048],
                                [0.0, 914.76700761, 348.73281015],
                                [0.0, 0.0, 1.0]])

        fx = new_camera_mtx[0, 0]  # ~917.04
        fy = new_camera_mtx[1, 1]  # ~914.76
        cx = new_camera_mtx[0, 2]  # ì•½ 479.64
        cy = new_camera_mtx[1, 2]  # ì•½ 348.73
        
        # [ì„¤ì •] goodFeaturesToTrack íŒŒë¼ë¯¸í„°
        MAX_CORNERS = 200        # ì¶”ì¶œí•  ìµœëŒ€ íŠ¹ì§•ì  ê°œìˆ˜
        MIN_CORNERS = 100        # ì¬ì¶”ì¶œ ì„ê³„ê°’
        QUALITY_LEVEL = 0.01     # ì½”ë„ˆ í’ˆì§ˆ (0.01 ~ 0.1)
        MIN_DISTANCE = 25        # íŠ¹ì§•ì  ê°„ ìµœì†Œ ê±°ë¦¬ (í”½ì…€)
        # =========================================================

        try:
            frame_reader = self.tello.get_frame_read()
        except Exception as e:
            self.log("ERROR", f"OpticalFlow: failed to get frame_read: {e}")
            self.is_optical_flow_running = False
            return

        prev_gray = None
        prev_pts = None
        prev_time = time.time()

        while self.is_optical_flow_running:
            # 1. í”„ë ˆì„ íšë“
            raw_frame = frame_reader.frame
            if raw_frame is None:
                time.sleep(0.01)
                continue

            # 2. ì™œê³¡ ë³´ì • (Undistort)
            frame = cv2.undistort(raw_frame, mtx, dist, None, new_camera_mtx)
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # =========================================================
            # [ì—ëŸ¬ ë°©ì§€ 1] í•´ìƒë„ ë³€ê²½ ê°ì§€
            # ì´ì „ í”„ë ˆì„ê³¼ í˜„ì¬ í”„ë ˆì„ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ë¦¬ì…‹í•©ë‹ˆë‹¤.
            # =========================================================
            if prev_gray is not None and prev_gray.shape != gray.shape:
                print(f"[Warning] Frame size changed: {prev_gray.shape} -> {gray.shape}. Resetting Flow.")
                prev_gray = None
                prev_pts = None

            # 3. íŠ¹ì§•ì  ì¶”ì¶œ (goodFeaturesToTrack ì‚¬ìš©)
            # ì´ˆê¸° ìƒíƒœì´ê±°ë‚˜, ì ì´ MIN_CORNERS ë¯¸ë§Œìœ¼ë¡œ ë–¨ì–´ì§€ë©´ ì¬ì¶”ì¶œ
            if prev_gray is None or prev_pts is None or len(prev_pts) < MIN_CORNERS:
                # goodFeaturesToTrackìœ¼ë¡œ íŠ¹ì§•ì  ì¶”ì¶œ
                prev_pts = cv2.goodFeaturesToTrack(
                    gray,
                    maxCorners=MAX_CORNERS,
                    qualityLevel=QUALITY_LEVEL,
                    minDistance=MIN_DISTANCE,
                    blockSize=7
                )
                
                if prev_pts is None or len(prev_pts) == 0:
                    # íŠ¹ì§•ì ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
                    with self.lock:
                        self.current_frame = frame
                    time.sleep(0.01)
                    continue
                
                self.log("DEBUG", f"ğŸ” Extracted {len(prev_pts)} feature points")
                prev_gray = gray
                prev_time = time.time()
                with self.lock:
                    self.current_frame = frame
                time.sleep(0.01)
                continue

            # 4. Optical Flow ê³„ì‚° (Lucas-Kanade)
            # =========================================================
            # [ì—ëŸ¬ ë°©ì§€ 2] try-exceptë¡œ ê°ì‹¸ì„œ í¬ë˜ì‹œ ë°©ì§€
            # =========================================================
            try:
                next_pts, status, _ = cv2.calcOpticalFlowPyrLK(
                    prev_gray, gray, prev_pts, None, **self.of_lk_params
                )
            except cv2.error as e:
                # OpenCV ì—ëŸ¬ ë°œìƒ ì‹œ(í¬ê¸° ë¶ˆì¼ì¹˜ ë“±) ë¦¬ì…‹í•˜ê³  ë„˜ì–´ê°
                print(f"[Error] calcOpticalFlowPyrLK failed: {e}")
                prev_gray = None
                prev_pts = None
                continue

            # ì¶”ì  ì„±ê³µí•œ ì ë“¤ë§Œ ìœ ì§€
            good_prev = prev_pts[status == 1]
            good_next = next_pts[status == 1]

            # ì¶”ì  ì ì´ ë„ˆë¬´ ì ìœ¼ë©´ ë‹¤ìŒ ë£¨í”„ì—ì„œ ì¬ìƒì„±í•˜ë„ë¡ ìœ ë„
            if len(good_prev) < MIN_CORNERS:
                self.log("DEBUG", f"âš ï¸ Feature points dropped to {len(good_prev)}, re-extracting...")
                prev_gray = None
                prev_pts = None
                continue

            vis = frame.copy()

            # =========================================================
            # ê±°ë¦¬ ê³„ì‚° ë¡œì§
            # =========================================================
            current_time = time.time()
            dt = current_time - prev_time
            prev_time = current_time

            vx_cm = self.tello.get_speed_x() * 10
            vy_cm = self.tello.get_speed_y() * 10
            # vz_cm = self.tello.get_speed_z() * 10
            yaw = self.tello.get_yaw()

            # yawë¥¼ ë¼ë””ì•ˆìœ¼ë¡œ ë³€í™˜
            yaw_rad = np.deg2rad(yaw)
            vx_forward = vx_cm * np.cos(yaw_rad) + vy_cm * np.sin(yaw_rad)  # ë“œë¡  ì•ë°©í–¥ ì†ë„
            vy_lateral = -vx_cm * np.sin(yaw_rad) + vy_cm * np.cos(yaw_rad) # ë“œë¡  ì¢Œìš°ë°©í–¥ ì†ë„

            tx = vx_forward / 100.0  # m/s
            dx = tx * dt        # ì´ë™ ê±°ë¦¬ (m)

            draw_count = 0
            valid_points_count = 0
            depth_measurements = []  # ìœ íš¨í•œ ê±°ë¦¬ ì¸¡ì •ê°’ ì €ì¥

            for p0, p1 in zip(good_prev, good_next):
                x0, y0 = p0.ravel()
                x1, y1 = p1.ravel()
                
                # u = (x1 - x0)
                
                # # í•„í„°ë§: ì›€ì§ì„ì´ ë„ˆë¬´ ì‘ê±°ë‚˜(ë…¸ì´ì¦ˆ), ë“œë¡ ì´ ë©ˆì¶°ìˆìœ¼ë©´ ìŠ¤í‚µ
                # if abs(u) < 0.1 or abs(dx) < 0.001:
                #     cv2.circle(vis, (int(x1), int(y1)), 2, (0, 150, 0), -1)
                #     continue

                # try:
                #     Z = (dx * fx) / u
                # except ZeroDivisionError:
                #     continue

                # ë…¸ì´ì¦ˆ í•„í„°ë§: ì´ë™ ê±°ë¦¬ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´(í˜¸ë²„ë§ ë“±) ê³„ì‚° ìŠ¤í‚µ
                if abs(dx) < 0.001:
                    continue

                # -----------------------------------------------------
                # [Step 1] ì •ë°€ ê°ë„ ê³„ì‚° (fx, fy ë°˜ì˜)
                # -----------------------------------------------------
                # a: ì´ì „ í”„ë ˆì„ ì ì˜ ê°ë„
                norm_x0 = (x0 - cx) / fx
                norm_y0 = (y0 - cy) / fy
                tan_a = math.sqrt(norm_x0**2 + norm_y0**2)
                
                # b: í˜„ì¬ í”„ë ˆì„ ì ì˜ ê°ë„
                norm_x1 = (x1 - cx) / fx
                norm_y1 = (y1 - cy) / fy
                tan_b = math.sqrt(norm_x1**2 + norm_y1**2)

                # ì¤‘ì‹¬ ë¶€ê·¼ ë…¸ì´ì¦ˆ í•„í„°ë§
                if tan_a < 0.01:
                    continue

                angle_a = math.atan(tan_a)
                angle_b = math.atan(tan_b)
                
                # -----------------------------------------------------
                # [Step 2] ê³µì‹ ì ìš©: Z = dx * sin(a) / sin(b - a)
                # -----------------------------------------------------
                # delta_angle (b - a)ëŠ” ì‹œì°¨(Parallax)ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
                delta_angle = angle_b - angle_a
                
                # ê°ë„ ë³€í™”ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´(ë¬´í•œëŒ€ ê±°ë¦¬ or ì •ì§€) ìŠ¤í‚µ
                if abs(delta_angle) < 1e-5:
                    continue

                try:
                    Z = dx * math.sin(angle_a) / math.sin(delta_angle)
                except ZeroDivisionError:
                    continue

                # ìœ íš¨ ê±°ë¦¬ í•„í„°ë§ (0 ~ 10m)
                if Z <= 0 or Z > 10.0:
                    cv2.circle(vis, (int(x1), int(y1)), 2, (0, 0, 255), -1) 
                    continue

                valid_points_count += 1
                depth_measurements.append(Z)
                
                # ì‹œê°í™”
                cv2.circle(vis, (int(x1), int(y1)), 3, (0, 255, 255), -1)
                cv2.line(vis, (int(x0), int(y0)), (int(x1), int(y1)), (0, 255, 255), 1)
                
                # í…ìŠ¤íŠ¸ ê°€ë…ì„± ì¡°ì ˆ (3ë²ˆì— 1ë²ˆ ì¶œë ¥)
                if draw_count % 3 == 0:
                    cv2.putText(vis, f"{Z:.1f}m", (int(x1) - 10, int(y1) - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (50, 255, 255), 1)
                draw_count += 1

            # í‰ê· /ì¤‘ê°„ê°’ ê±°ë¦¬ ê³„ì‚°
            avg_depth = np.mean(depth_measurements) if depth_measurements else 0.0
            median_depth = np.median(depth_measurements) if depth_measurements else 0.0

            # ì •ë³´ í‘œì‹œ
            print(self.tello.get_current_state())
            info_text = f"Features: {len(good_next)} | Speed v_forward: {vx_forward/100:.2f} m/s | Speed v_lateral: {vy_lateral/100:.2f} m/s | Yaw: {yaw} degree | Valid: {valid_points_count}"
            cv2.putText(vis, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            # cv2.putText(vis, f"query speed: {self.tello.query_speed()}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            # í‰ê·  ê±°ë¦¬ í‘œì‹œ
            if depth_measurements:
                depth_text = f"Avg Depth: {avg_depth:.2f}m | Median: {median_depth:.2f}m"
                cv2.putText(vis, depth_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

            with self.lock:
                self.current_frame = vis

            # ë‹¤ìŒ í”„ë ˆì„ ì¤€ë¹„
            prev_gray = gray.copy()
            prev_pts = good_next.reshape(-1, 1, 2)

            time.sleep(0.01)


    def start_optical_flow(self):
        """Optical Flow depth ì¶”ì • ìŠ¤ë ˆë“œ ì‹œì‘"""
        if not self.is_connected:
            self.log("ERROR", "Cannot start optical flow: Not connected")
            return False
        if self.is_optical_flow_running:
            self.log("WARNING", "Optical flow already running")
            return False

        self.is_optical_flow_running = True
        threading.Thread(target=self.optical_flow_thread, daemon=True).start()
        self.log("INFO", "Optical flow depth thread started")
        return True


    # ----------------------
    # Depth feed (MJPEG) - ì»¬ëŸ¬ë§µìœ¼ë¡œ ì œê³µ
    # ----------------------
    def get_depth_colormap_jpeg(self):
        with self.lock:
            if self.current_depth_map is None:
                return None
            depth = self.current_depth_map.copy()

        # 0 ê°’(ì—†ëŠ” ì§€ì )ì€ minìœ¼ë¡œ ì²˜ë¦¬í•´ì„œ ì‹œê°í™” ì™œê³¡ ë°©ì§€
        mask = depth > 0
        if not np.any(mask):
            return None

        # normalize to 0-255 for colormap
        depth_nonzero = depth.copy()
        # clip extremes
        vmin = np.percentile(depth_nonzero[mask], 5)
        vmax = np.percentile(depth_nonzero[mask], 95)
        if vmin == vmax:
            vmax = vmin + 1e-3
        norm = np.zeros_like(depth_nonzero, dtype=np.uint8)
        clip = np.clip(depth_nonzero, vmin, vmax)
        norm = ((clip - vmin) / (vmax - vmin) * 255.0).astype(np.uint8)

        # fill zeros with 0 (black)
        norm[~mask] = 0

        colormap = cv2.applyColorMap(norm, cv2.COLORMAP_JET)
        # return JPEG bytes
        _, buffer = cv2.imencode('.jpg', colormap, [cv2.IMWRITE_JPEG_QUALITY, 80])
        return buffer.tobytes()

    # ----------------------
    # ëª…ë ¹ ì‹¤í–‰ (ê¸°ì¡´)
    # ----------------------
    def get_current_frame_jpeg(self):
        """í˜„ì¬ í”„ë ˆì„ì„ JPEGë¡œ ë°˜í™˜"""
        with self.lock:
            if self.current_frame is not None:
                _, buffer = cv2.imencode('.jpg', self.current_frame,
                                        [cv2.IMWRITE_JPEG_QUALITY, 80])
                return buffer.tobytes()
        return None

    def execute_command(self, command):
        """ë“œë¡  ëª…ë ¹ ì‹¤í–‰"""
        if not self.is_connected or not self.tello:
            return {'success': False, 'message': 'Not connected to Tello'}

        try:
            if command == 'takeoff':
                self.log("INFO", "ğŸš Taking off...")
                self.tello.takeoff()
                time.sleep(3)
                self.log("SUCCESS", "Takeoff successful")
                return {'success': True, 'message': 'Takeoff successful'}

            elif command == 'land':
                self.log("INFO", "ğŸ›¬ Landing...")
                self.tello.land()
                time.sleep(2)
                self.log("SUCCESS", "Landing successful")
                return {'success': True, 'message': 'Landing successful'}

            elif command == 'emergency':
                self.log("WARNING", "ğŸš¨ Emergency stop!")
                self.tello.emergency()
                return {'success': True, 'message': 'Emergency stop'}

            elif command == 'up':
                self.tello.move_up(30)
            elif command == 'down':
                self.tello.move_down(30)
            elif command == 'left':
                self.tello.move_left(30)
            elif command == 'right':
                self.tello.move_right(30)
            elif command == 'forward':
                # self.tello.move_forward(30)
                # self.tello.go_xyz_speed(30, 0, 0, 100)
                self.tello.send_rc_control(left_right_velocity=0, forward_backward_velocity=100, up_down_velocity=0, yaw_velocity=0)
            elif command == 'back':
                self.tello.move_back(30)
            elif command == 'cw':
                self.tello.rotate_clockwise(30)
            elif command == 'ccw':
                self.tello.rotate_counter_clockwise(30)
            else:
                return {'success': False, 'message': f'Unknown command: {command}'}

            time.sleep(1.0)
            self.log("DEBUG", f"Command {command} completed")
            return {'success': True, 'message': f'Command {command} executed'}

        except Exception as e:
            self.log("ERROR", f"Command execution error: {e}")
            return {'success': False, 'message': str(e)}

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.is_logging = False
        # Stop optical flow if running
        # ë…¹í™” ì¤‘ì´ë©´ ì¤‘ì§€
        if self.is_recording:
            try:
                self.stop_recording()
            except:
                pass
        try:
            self.stop_optical_flow()
        except:
            pass
        # Stop streaming
        try:
            self.stop_streaming()
        except:
            pass
        if self.inference_engine:
            try:
                self.inference_engine.close()
            except:
                pass
